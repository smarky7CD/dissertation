We start by (re)introducing theC PDS that we consider in this chapter -- the count-min sketch and the Top-K (HeavyKeeper). We will describe their original specification, the probabilistic guarantees they provide, and give a detailed description of their Redis implementation. We depart from our use of the generic data structure's syntax of~\cite{clayton2019}, instead using an ad-hoc syntax that better matches how the structures are defined and implemented in Redis. 

\subsection{Count-min Sketches}
\label{sec:cms-intro}

\begin{figure*}[h]
    \centering
\begin{pcvstack}[boxed,space=1em]
\begin{pchstack}
    \begin{pcvstack}[space=0.5em]
        \procedure[linenumbering, headlinecmd={\vspace{.1em}\hrule\vspace{.2em}}]{\rCMS.$\setupS(pp)$}{%
        \varepsilon, \delta \gets pp \\ 
        m \gets \left\lceil \frac{e}{\varepsilon} \right\rceil\\
        k \gets  \left\lceil \ln(\frac{1}{\delta}) \right\rceil\\
        h(\circ) \gets \murmurtwo(\circ) \bmod m\\
        \sigma \gets \zeros(k,m)\\
        \pcreturn \top
        }
       \end{pcvstack}
    \begin{pcvstack}[space=0.5em]
        \procedure[linenumbering, headlinecmd={\vspace{.1em}\hrule\vspace{.2em}}]{\rCMS.$\insS(x, \sigma, v)$}{%
            (p_1,\ldots,p_k) \gets h(x,1),\ldots,h(x,k)\\
            \pcfor i \in [k]\\
            \t \sigma[i][p_i] += v\\
            \pcreturn  \mathrm{min}_{i \in [k]}\{\sigma[i][p_i]\}
        }
        \procedure[linenumbering, headlinecmd={\vspace{.1em}\hrule\vspace{.2em}}]{\rCMS.$\qryS(x, \sigma)$}{%
            (p_1,\ldots,p_k) \gets h(x,1),\ldots,h(x,k)\\
            \pcreturn  \mathrm{min}_{i \in [k]}\{\sigma[i][p_i]\}
        }
    \end{pcvstack}	
\end{pchstack}		
\end{pcvstack}
\caption[The Redis CMS Structure.]{Redis count-min sketch algorithms. 
The analogous functions in the Redis API are: $\rCMS.\setupS$ is \textsf{CMS.INITBYPROB}, $\rCMS.\insS$ is \textsf{CMS.INCRBY}, and $\rCMS.\qryS$ is \textsf{CMS.QUERY}.
We refer to a Redis count-min sketch initialized with $\varepsilon, \delta \in (0,1)$ as CMS[$\varepsilon, \delta$].} 
\label{fig:redis-cms}
\end{figure*}

A count-min sketch supports frequency estimates, i.e. estimates of the number of times a particular element occurs in a data set. Originally introduced in~\cite{cormode2005improved}, a count-min sketch consists of a $k \times m$ array $\sigma$ of (initially zero) counters, and $k$ pairwise independent hash functions $h_1, ..., h_k$ that map between the universe~$\mathcal{U}$ of data items and $[m]$.

An element $x$ is added to a count-min sketch by computing 
$(p_1,p_2,\ldots,p_k) \gets h(x,1),\ldots,h(x,k)$, 
 then adding $1$ to each of the counters at $\sigma[i][p_i]$ for $i \in [k]$. This extends in the obvious way to insertions of $v$ instances of an element at a time. 
A frequency estimate for $x$ is computed as $\hat{n}_x = \ \mathrm{min}_{i \in [k]} \{\sigma[i][p_i]\}$. A count-min sketch may produce overestimates of the true frequency, but never underestimates.

For any $\varepsilon,\delta \, {\geq}\, 0$, any $x {\in}\, \mathcal{U}$, and any collection of data $\mathcal{C}$ stored by the count-min sketch (over $\mathcal{U}$) of length $N$, it can be guaranteed by appropriate setting of parameters that $\Pr[\hat{n}_x - n_x \,{>}\, \varepsilon N] \,{\leq}\, \delta$, where $n_x$ is the true frequency of $x$. Specifically, we can take $m \gets \lceil{ e/\varepsilon \rceil}$, $k \gets \lceil{ \ln{(1/\delta)} \rceil}$. This correctness bound holds when the individual hash functions are sampled from a pairwise-independent hash family $H$ (see~\cite{cormode2005improved} for a proof). It further assumes that insertions are done in the honest setting. That is, $\mathcal{C}$ and the queried element $x$ are independent of the internal randomness of the structure (the random choice of the hash functions). 


In Redis, a count-min sketch is initialized by the user calling $\rCMS.\setupS(\varepsilon, \delta)$. We will refer to the resulting sketch as CMS[$\varepsilon, \delta$]. The dimensions $m, k$ of the count-min sketch are then calculated as above, and a $k \times m$ array of zeros is initialized. We note that it is also possible to initialize the structure from the dimensional parameters $m, k$, rather than deriving them from $\varepsilon, \delta$. Insertions and membership queries on any element $x$ are carried out in the same way as in the original structure, using the commands $\rCMS.\insS(x, \sigma, v)$ and $\rCMS.\qryS(x, \sigma)$; both return the frequency estimate of $x$.
The analogous functions in Redis are called \textsf{CMS.INITBYPROB}, \textsf{CMS.INCRBY} and \textsf{CMS.QUERY}, respectively. 

To instantiate the $k$ pairwise independent hash functions, Redis uses $\murmurtwo$ with a per row seed equal to the row index, i.e. $h_1(x) \gets h(x, 1), ..., h_k(x) \gets h(x, k)$, where the syntax~$h(x,i)$ means $\murmurtwo$ evaluated on input~$x$ with seed~$i$. For full details of count-min sketches in Redis, see~\Cref{fig:redis-cms}.

 We point out that using fixed hash functions violates the honest setting assumptions that are required for the guarantees on frequency estimation errors in~\cite{cormode2005improved}. We will leverage this and the properties of~$\murmurtwo$ in our attacks to cause large frequency overestimates. 

\subsection{Top-K}

\begin{figure*}[h]
    \centering
	\begin{pcvstack}[boxed,space=1em]
		\begin{pchstack}
			\begin{pcvstack}[space=0.5em]
        %
        \procedure[linenumbering, headlinecmd={\vspace{.1em}\hrule\vspace{.2em}}]{\rTK.$\setupS(pp)$}{
        %$\mathsf{INIT}(w,d,\mathrm{decay},K)$}{%
        	   m, k, \mathrm{decay}, K \gets pp \\
	   \seed \gets 1919 \\ 
        	   h(\circ) \gets \murmurtwo(\circ) \bmod m\\
			   h_\mathit{fp} \gets \murmurtwo(\circ)\\
            \pcfor i \in [k] \\
            \t \sigma[i] \gets [(\star,0)]\times m\\
            H \gets \mathsf{initminheap}(K)\\
            \pcreturn \top
        }
        %
        %
        \procedure[linenumbering, headlinecmd={\vspace{.1em}\hrule\vspace{.2em}}]{\rTK.$\qryS(x, \sigma)$}{
        %$\mathsf{QUERY}(A,x)$}{%
        (p_1,\ldots,p_k) \gets h(x,1),\ldots,h(x,k)\\
        \fp_{x} \gets h_\mathit{fp}(x,\seed)\\
        \cnt_x \gets 0\\
        \pcfor i \in [k] \\
        \t \pcif  \sigma[i][p_i].\fp = \fp_x \\
        \t \t \cnt {\gets} {\sigma[i][p_i]}.\cnt\\
        \t \t  \cnt_x{\gets}{\max}\left\{\cnt_x, \cnt\right\}\\
        \pcreturn \cnt_x
        }
        %
        \procedure[linenumbering, headlinecmd={\vspace{.1em}\hrule\vspace{.2em}}]{\rTK.$\listS(\sigma)$}{
        %$\mathsf{KLIST}(\sigma)$}{%
        T \gets H.\mathsf{list}()\\
        \pcreturn T
        }
        %
    \end{pcvstack}
			\begin{pcvstack}[space=0.5em]
            \procedure[linenumbering, headlinecmd={\vspace{.1em}\hrule\vspace{.2em}}]{\rTK.$\insS(x, \sigma)$}{
        %$\mathsf{ADD}(A,H,\mathrm{decay})$}{%
			r \gets \mathrm{nil}\\
            (p_1,\ldots,p_k) \gets h(x,1),\ldots,h(x,k)\\
            \fp_{x} \gets h_\mathit{fp}(x,\seed)\\
            \cnt_x \gets 0\\
            \pcfor i \in [k]\\
            \t{\pcif} \sigma[i][p_i].\fp \, {\not\in} \{\fp_x, {\star}\}\\
            \t \t r \getsr \left[0,1\right)\\
            \t \t \pcif r \leq \mathrm{decay}^{\sigma[i][p_i].\cnt}\\
            \t\t\t \sigma[i][p_i].\cnt \,{-}{=}\, 1\\
            \t\pcif  \sigma[i][p_i].\cnt = 0 \\
            \t\t \sigma[i][p_i].\fp  \gets \fp_x \\
            \t\pcif \sigma[i][p_i].\fp = \fp_x \\
            \t\t \sigma[i][p_i].\cnt \,{+}{=}\, 1 \\
            \t\t \pcif  \sigma[i][p_i].\cnt > \cnt_x \\
            \t\t\t \cnt_x \gets \sigma[i][p_i].\cnt \\
            \pcif \cnt_x \in H \\
            \t H.\mathsf{update}(x,\cnt_x)\\
            \pcelseif \cnt_x > H.\mathsf{getmin}() \\
			\t r \gets H.\mathsf{getmin}()\\
            \t H.\mathsf{poppush}(x,\cnt_x)\\
            \pcreturn r
        }
        \end{pcvstack}
        \end{pchstack}
        \end{pcvstack}
	\caption[The Redis Top-K Structure.]{Redis Top-K structure algorithms. The analogous functions in the Redis API are: $\rTK.\setupS$ is \textsf{TOPK.RESERVE}, $\rTK.\insS$ is \textsf{TOPK.ADD}, $\rTK.\qryS$ is \textsf{TOPK.COUNT}, and $\rTK.\listS$ is \textsf{TOPK.LIST}.
		  We refer to a Redis Top-K structure initialized with $pp=m,k,\mathrm{decay}, K$ as TK[$m,k,\mathrm{decay}, K$]. 
	} 
	\label{fig:redis-topk}	
\end{figure*}

A Top-K structure, originally introduced as the HeavyKeeper in~\cite{yang2019heavykeeper}, solves the approximate top-$K$ problem. 

The exact version of the problem is defined as follows: given elements of a data collection~$\mathcal{C} \subseteq  \{ e_1,e_2,...,e_m \}$ with associated frequencies~$(n_{e_1},n_{e_2},...,n_{e_m})$, we can order the elements~$\{ e^{*}_{1},e^{*}_{2},...,e^{*}_{M} \}$ such that~$(n^{*}_{e_1} \geq n^{*}_{e_2} \geq ... \geq n^{*}_{e_M})$. Then, for some~$K \in \mathbb{Z}^{+}$, we output the set of elements~$\{ e^{*}_{1},e^{*}_{2},...,e^{*}_{K} \}$ with the~$K$ largest frequencies~$(n^{*}_{e_1} \geq n^{*}_{e_2} \geq ... \geq n^{*}_{e_K})$. Given space linear in the stream this is trivial to solve exactly. However, by the pigeonhole principle, it is not possible to find an exact solution with space less than linear (see~\cite{Roughgarden_Valiant} for a formal impossibility argument).
A common technique is to place a small data structure of size~$O(K)$, like a heap or list, on top of a compact frequency estimator. By updating this small structure at most once upon an insertion of each element, we can approximate this top-$K$ set~\cite{mandal2018topkapi,metwally2006}. Using this technique we will obtain the~$K$ elements with the largest estimated frequencies. 

The Top-K structure is represented by a $k{ \times} m$ matrix~$\sigma$. Each entry in~$\sigma$ is an $(\fp,\cnt)$ pair, where~$\fp$ is a fingerprint of the element that ``owns'' the counter, and~$\cnt$ is said element's recorded count. These entry pairs are initialized to the distinguished symbol~$\star$ and zero, respectively. Associated with each row is a hash function that maps elements in~$\mathcal{U}$ to $[m]$, i.e. $k$ hash functions $h_1,...,h_k$. The fingerprint hash function $h_\mathit{fp}$ maps elements in~$\mathcal{U}$ to $\{ 0,1 \}^{\lambda_{\mathit{fp}}}$, for some desired fingerprint length~$\lambda_{\mathit{fp}}$. Further, we initialize a min-heap~$H$ of maximal size~$K$ to store the elements with the~$K$ largest estimated frequencies. Lastly, a~$\mathrm{decay}$ value is set, which is used to decrement a counter when a specific condition is hit. 

To insert an element~$x$, we start by computing $(p_1,...,p_k) \gets (h_1(x),\ldots,h_k(x))$. We then compute the fingerprint $\fp_x$ associated with the element~$x$ as $h_\mathit{fp}(x)$. We also set a variable~$\cnt_x \gets 0$. We then go row by row (indexed by~$i \in [k]$), with the following cases:
\begin{enumerate}
    \item \textbf{if} $\fp^{*} = \star$, 
	where~$\fp^{*}$ is the current fingerprint value at matrix position~$(i,p_i)$, \textbf{then} we set the counter value to~$1$, the fingerprint to~$\fp_x$, and if~$\cnt_x < 1 : \cnt_x \gets 1$.
    \item \textbf{else if} $\fp_x = \fp^{*}$,
    we add~$1$ to the counter value, and if~$\cnt_x < c : \cnt_x \gets c$, where $c$ is the current counter value at matrix position~$(i,p_i)$. 
    \item \textbf{else}
    we select a random value~$r \getsr [0,1)$. If~$r < \mathrm{decay}^{c}$, where~$c$ is the current counter value at matrix position~$(i,p_i)$, we decrement the counter value stored at this position. If, after decrementing, this value is~$0$, we then set the counter value to~$1$, the fingerprint to~$\fp_x$, and if~$\cnt_x < 1 : \cnt_x \gets 1$. This is the so-called probabilistic decay process. 
\end{enumerate}

If, after this procedure, it is such that $x \in H$, we update the entry in the heap based on the current value of~$\cnt_x$. Else, we check that~$\cnt_x > H.\mathsf{min}$, and if so we remove the min entry in~$H$ and replace it with~$(x,\cnt_x)$. This ensures that we are keeping an accurate account of the~$K$ highest estimated frequencies in~$H$. 

Top-K provides approximate answers to frequency queries for any element $x$, by 
computing $(p_1,\ldots,p_k) \gets (h_1(x),\ldots,h_k(x))$ and~$\fp_x \gets h_\mathit{fp}(x)$, and returning $\hat{n}_x = \max_{i \in [k]} \{\sigma[i][p_i]\}$ where $\sigma[i][p_i].\fp = \fp_x$. % removed ~ for formatting reasons
If none of the fingerprints in this set of buckets equals~$\fp_x$, then~$0$ is returned. 
Top-K returns the estimated top-$K$ elements by returning all the pairs of items and estimated counts stored in~$H$. 


In~\cite{yang2019heavykeeper}, a probabilistic guarantee for estimation error magnitude is presented, assuming that each $\sigma[i][j]$ has a sole owner throughout the processing of the entire stream. However, the statement lacks precision, and its proof is flawed, thus we will not restate it (see instead~\cite{markelon23} for a meaningful result). Moreover, the results in~\cite{yang2019heavykeeper} rely on a no-fingerprint collision (NFC) assumption, ensuring that all frequency estimates satisfy $\hat{n}_x \leq n_{x}$, where $n_x$ is the true frequency of $x$, i.e. Top-K strictly underestimates frequencies. While not formally defined in the original paper, a rigorous definition is given in~\cite{markelon23}, characterizing NFC as the assumption that elements hashing to the same row position in any row do not share a fingerprint. This assumption is reasonable for practical sizes of $\mathcal{U}$ and a sufficiently large fingerprint space.

To initialize a Top-K structure in Redis, the user specifies $k, m$, $\mathrm{decay}$, and $K$, by calling \rTK.$\setupS(k, m, \mathrm{decay}, K)$. (The analogous function in Redis is called \textsf{TOPK.RESERVE}.) We refer to the resulting structure as TK[$k, m, \mathrm{decay}, K$].
The hash functions for each row are again computed as $h_1(x) \gets h(x, 1), ..., h_k(x) \gets h(x, k)$, with $h$ set to $\murmurtwo \bmod m$. The fingerprint hash function is computed as $h_\mathit{fp} \gets h(x, \seed)$, with $h_\mathit{fp}$ set to $\murmurtwo$ ($\lambda_{\mathit{fp}} = 32$) with a fixed $\seed = 1919$. The $\mathrm{decay}$ value is by default set to~$0.9$. 

Insertions and frequency queries on an element $x$ then proceed as described above, through the $\rTK.\insS(x, \sigma)$ and $\rTK.\qryS(x, \sigma)$ functionalities. Similar to the count-min sketch, multiple instances of an element can be added to the Top-K, however this is implemented through repeated invocations of the insert algorithm described above. 
To return the top-$K$ elements, one invokes $\rTK.\listS(\sigma)$. (The analogous functions in Redis are called \textsf{TOPK.ADD}, \textsf{TOPK.COUNT} and \textsf{TOPK.LIST}, respectively.) For full details of the Redis Top-K structure, see~\Cref{fig:redis-topk}. 

We will show that the specific implementation choices that Redis makes leads to security issues. Specifically, we give attacks that block the true~$K$ most frequent elements from being reported in the top-$K$ estimation (with overwhelming probability) whether or not these elements are known to the attacker before the attack. Further, we show that one is able to trivially violate the NFC assumption and cause the Redis Top-K structure to allow for frequency overestimates.