\chapter{Background}\label{chap:background}

\section{Notation}

\paragraph{Bitstring and Set Operations}

Let $\bits^*$ denote the set of bitstrings and let~$\emptystr$ denote the empty
string. Let $X \cat Y$ denote the concatenation of bitstrings~$X$ and~$Y$.  When~$\col$ is an abstract data-object (e.g., a (multi)set, a list) and~$e$ is an object that can be appended (in some understood fashion) to~$\col$, we overload the $\cat$ operator and write $\col \cat e$.

Let $x \getsr \setX$ denote sampling~$x$ from a set~$\setX$ according to the distribution associated with~$\setX$; if~$\setX$ is finite and the distribution is unspecified, then it is uniform. Moreover, we denote by $\mathsf{U}(S)$ the uniform distribution on the (finite or uncountable) set $S\neq\emptyset$, and by $\mathsf{G}(p)$ be the geometric distribution for success probability $p$.

Let $[i..j]$ denote the set of integers $\{i, \ldots, j\}$; if $i > j$, then define $[i..j] = \emptyset$. For all $m \geq 2$, let $[m] = \{1,2,\ldots,m\}$.

Let $\mathcal{A}$ and $\mathcal{B}$ be sets. We take $\mathcal{A} \cup \mathcal{B}$ to be the union of the sets, $\mathcal{A} \cap \mathcal{B}$ to be the intersection of the sets, and $\mathcal{A} \setminus \mathcal{B}$ to be set-theoretic difference of $\mathcal{A}$ and $\mathcal{B}$.

\paragraph{Functions}

Let $\Func(\setX,\setY)$ denote the set of functions $f:\setX\to\setY$. For every function~$f: \setX \to \setY$, define $\id^f: \{\emptystr\} \times \setX \to \setY$ so that $\id^f(\emptystr, x) = f(x)$ for all $x$ in the domain of~$f$. This allows us to use unkeyed hash functions $H$ in situations where, syntactically, a function is required to take a key along with its input. 

\paragraph{Arrays and Tuples}

We use the distinguished symbol~$\star$ to mean that a variable is uninitialized. By $[\text{item}] \times \ell$ for~$\ell \,{\in}\, N$ we mean a vector of $\ell$ replicas of $\text{item}$. We use $\zeros(m)$ denote a function that returns an $m$-length array of 0s and, likewise, $\zeros(k,m)$ to denote a function that returns an $k \times m$ array of 0s.  We index into arrays (and tuples) using $[\cdot]$ notation; in particular, if $R$ is a function returning a $k$-tuple, we write $R(x)[i]$ to mean the $i$-th element/coordinate of $R(x)$.  If~$X{=}\,(x_1,x_2,\ldots,x_t)$ is a tuple and $\set{S}$ is a set, we overload standard set operators (e.g., $X \,{\subseteq}\, \set{S}$) treating the tuple as a set; if we write $X \setminus \set{S}$, we mean to remove all instances of the elements of~$\set{S}$ from the tuple~$X$, returning a tuple~$X'$ that is ``collapsed'' by removing any now-empty positions.

\section{A Syntax for Data Structures}\label{subsec:syntax}

We present a syntax for data structures first provided by~\cite{clayton2019}. While originally used to describe a variety of probabilistic data structures, the syntax is appropriately general. A syntactic formalization of data structures in this way not only allows us to elegantly describe numerous data structures, but also craft security definitions that are directly related to the operations the data structure allows. We will do exactly this throughout the rest of this work.

We start by fixing three non-empty sets~$\set{D},\set{R},\set{K}$ of \emph{data objects}, \emph{responses} and \emph{keys}, respectively.  Let $\mathcal{Q}\subseteq \Func(\mathcal{D},\mathcal{R})$ be a set of allowed \emph{queries}, and let $\mathcal{U} \subseteq \Func(\mathcal{D},\mathcal{D})$ be a set of allowed data-object \emph{updates}.  A {\em data structure} is a tuple $\Pi =
(\Rep,\Qry,\Up)$, where:

\begin{itemize}[leftmargin=.2in]
  \item $\Rep\colon \keys \times \mathcal{D} \to \{0,1\}^* \cup \{\bot\}$ is a
  (possibly) randomized {\em representation algorithm}, taking as input a key $\key \in
  \keys$ and data object $\col \in \mathcal{D}$, and outputting the
  representation $\pub \in \{0,1\}^*$ of $D$, or $\bot$ in the case of a
  failure. We write this as $\pub \gets \Rep_\key(\col)$.
%
  \item $\Qry\colon \keys \times \{0,1\}^* \times \mathcal{Q} \to \mathcal{R} \cup \{\bot\}$
  is a deterministic {\em query-evaluation algorithm}, taking as input $\key \in
  \keys$, $\pub \in \{0,1\}^*$, and $\qry \in \mathcal{Q}$, and outputting an
  answer $a \in \mathcal{R}$, or $\bot$ in the case of a failure. We write this as $a \gets \Qry_\key(\pub,\qry)$.
%
  \item $\Up\colon \keys \times \{0,1\}^* \times \mathcal{U} \to \{0,1\}^* \cup
  \{\bot\}$ is a (possibly) randomized {\em update algorithm}, taking as input $\key \in
  \keys$, $\pub \in \{0,1\}^*$, and $\up \in \mathcal{U}$, and outputting an
  updated representation $\pub'$, or $\bot$ in the case of a failure. We write
  this as $\pub' \gets \Up_\key(\pub,\up)$.
\end{itemize}

Allowing each of the algorithms to take a key~$K$ permits one to separate (for some
security notion) any secret randomness used across data structure operations,
from per-operation randomness (e.g., generation of a salt). Note that this syntax admits the
common case of \emph{unkeyed} data structures, by setting
$\keys=\{\emptystring\}$. Moreover, we can set $\keys=\mathsf{priv}$ to be a private key and allow the corresponding public key $\mathsf{pub}$ to be a public parameter in the case the data structure relies on asymmetric cryptographic primitives.  

Both~$\Rep$ and the~$\Up$ algorithm can be viewed (informally) as mapping data
objects to representations ---~explicitly so in the case of~$\Rep$, and
implicitly in the case of~$\Up$~--- so we allow~$\Up$ to make per-call random
choices, too. 

Note that $\Up$ takes a function operating on data objects as an argument, even
though $\Up$ itself operates on \emph{representations} of data objects. This is
intentional, to match the way these data structures generally operate.
In a data structure representing a set or multiset, we often think of performing
operations such as `insert $x$' or `delete $y$'. When the set or multiset is not
being stored, but instead modeled via a representation, the representation must
transform these operations into operations on the actual data structure it is
using for storage. This is common for operation on probabilistic data structures. 

We also note that the query algorithm $\Qry$ is deterministic, which reflects the overwhelming majority of data structures in practice. Allowing~$\Qry$ to be randomized would allow for a greater degree of syntactic expressiveness, particularly for some data structures that provide privacy guarantees. However, it can make it more difficult to craft correctness properties in that it may be difficult to discern the errors caused by an adaptive adversary versus ``intended'' error arising from the randomized query algorithm. Care must be taken when both designing structures and defining security properties to ensure issues do not arise from this.  

\section{Streaming Data}

A \emph{stream} data-object~$\streamvar{S} = e_1,e_2,\ldots$ is a finite sequence of elements $e_i \in \set{U}$ for some universe~$\set{U}$.  
The elements of a stream are not necessarily distinct, and the (stream) frequency of some $x \in \set{U}$ is $|\{i: e_i=x \}|$.  
From the perspective of the PDS, the stream is presented one element at a time, with no buffering or ``look ahead".  
That is, processing of a stream is performed in order, and the processing of $e_i$ is completed before the processing of $e_{i+1}$ may begin; once~$e_i$ has been processed, it cannot be revisited.

\section{Related Works}

We now provide a summary of related work for the classes of data structures that we focus on in this dissertation.

\subsection{Compact Probabilistic Data Structures and Compact Frequency Estimators}

\subsubsection{Approximate Set Membership Data Structures}

The first works to explore CPDS in a provable security style focused on the Bloom filter~\cite{bloom1970space}. The Bloom filter admits approximate set-membership queries. The structure is widely used in many computing contexts, such as databases~\cite{chang2008bigtable}, networking~\cite{broder2004network}, distributed systems~\cite{tarkoma2011theory}, and search~\cite{goodwin2017bitfunnel}. 

Naor and Yogev were the first to consider settings in which inputs and queries may be chosen by an adaptive adversary and formally investigate attacks that can occur in such a setting~\cite{naor2015bloom}. Their results show that adversaries can find queries that are guaranteed to be false positive for a given instantiation of a filter and data collection. They formalized a notion of adversarial correctness for a modified Bloom filter structure of their own construction and provide a correctness bound for it.  Clayton et al.~\cite{clayton2019} extend this work by considering stronger adversaries. They allow for the adversary to insert elements into the structure after the adversary has started to issue queries -- that is, they consider a fully mutable setting.  They find that the basic Bloom filter is vulnerable to adversarial manipulation, which can increase false positives to nearly $100\%$. To secure it, they recommend adding a unique salt in an immutable setup, or using a private representation, keyed hash functions, and insertion thresholds in a mutable setting. Further, they formalize a notion of adversarial correctness that extends past only Bloom filters, also concretely analyzing the counting filter~\cite{fan2000summary} and the Count-min sketch~\cite{cormode2005improved}. FiliÄ‡ et al.~\cite{FPUV22,filic2025deletions} further analyze the adversarial correctness of Bloom filters and Cuckoo filters (another approximate membership data structure) in a simulation style security notion. They reach similar conclusions to~\cite{clayton2019}. 

\subsubsection{HyperLogLog}

The HyperLogLog (HLL)~\cite{flajolet2007hyperloglog} is a CPDS that provides a compact representation of a set and can accurately approximate the number of distinct elements in the set (i.e., the set's cardinality). Patterson and Raynal~\cite{PatersonR22} provide a provable security treatment of the HLL. They first present attacks which exploit the use of fixed and publicly computable hash function in the HLL to cause large cardinality estimate errors. They then show that by switching these hash functions for a secretly keyed primitive that (even in the setting where an adversary has complete access to the internal state of the structure) the structure remains secure in terms of conserving the non-adversarial correctness guarantees of the structure. Prior to this, Revirigeo and Ting provide attacks against the HLL in a model where the adversary has access to a ``shadow'' device that mirrors the structure that is being attacked~\cite{reviriego2020security}. Patterson and Raynal point out this setting in unrealistic, but nonetheless improve the attack in this model. 


\subsubsection{Compact Frequency Estimators}

Recall that compact frequency estimators are a class of CPDS that compactly represent a collection of streaming data (usually modeled as a multiset), and provide approximately correct frequency estimates (that is, the number of times any particular element has appeared in the stream). Alternately, compact frequency estimators can be viewed as providing a compact representation of the frequency distribution of a particular data stream. 

As previously stated, Clayton et al. were the first to examine compact frequency estimators from a provable security perspective~\cite{clayton2019}. They specifically examined the Count-min sketch and presented attacks that could cause large frequency estimation error when the internals state of the structure or the hash functions used by the structure were made available to the adversary. They were able to prove security of the structure when the internal state of the structure is kept private and a secretly keyed primitive was used in place of the usual hash functions. However, their defined adversarial goal was very conservative. Any fixed amount of frequency estimation error was considered a win for the adversary, rather than an accumulated error that surpassed that of the non-adversarial correctness guarantee. Further, their construction relied on a thresholding technique, in which the structure would not accept any more updates after a bounded number of insertions -- something that in practice is unrealistic.  

\subsection{Probabilistic Skipping-Based Data Structures}

\subsubsection{Self-Balancing and Self-Organizing Data Structures}

Although PSDS share conceptual similarities with self-balancing and self-organizing data structures, they differ fundamentally in their guarantees and methodological approach. 
Notably, self-organizing data structures have been extensively analyzed under adversarial models where input sequences are deliberately constructed to degrade performance, whereas the corresponding analysis for PSDS against adaptive adversaries remains a significant open problem. Similarly, self-balancing data structures have been studied extensively under worst-case analyses that inherently account for adversarial strategies.

\emph{Self-organizing data structures}~\cite{albers2005self}, whether randomized or deterministic, dynamically adjust their internal ordering of elements to optimize performance based on a given (potentially adversarial) sequence of input requests. For instance, self-organizing lists may employ the move-to-front heuristic, where accessed elements are relocated to the front of the list, or the transpose method, where elements swap positions with their predecessors when accessed. Similarly, splay trees~\cite{sleator1985self} rotate frequently accessed nodes closer to the root to reduce future access times. This approach has been shown to be challenging in adaptive adversarial settings, with (randomized) self-organizing lists incurring a cost at least three times that of the optimal reordering strategy \cite{reingold1994randomized}. 

\emph{Self-balancing} data structures, such as Red-Black trees~\cite{bayer1972symmetric} and AVL trees~\cite{adel1962algorithm}, \emph{deterministically} ensure an upper-bound on node depth, thereby providing worst-case performance guarantees for search operations. This deterministic approach is also exemplified by the deterministic skip list~\cite{munro1992deterministic}, which enforces an optimal structure by carefully promoting inserted nodes and their neighborhoods to appropriate levels. While these structures guarantee bounded search path lengths (even in adversarial settings), they require complex re-balancing mechanisms. In steep contrast, PSDS, such as the treap~\cite{seidel1996randomized} and the original skip list~\cite{pugh}, offer comparable expected performance, achieved through simple, probabilistic updating mechanisms. This presents a clear trade-off: deterministic structures provide absolute performance guarantees at the cost of implementation complexity, while probabilistic alternatives offer simplicity, albeit, with only probabilistic guarantees. In this work, we investigate whether we can maintain the implementation simplicity of probabilistic data structures while preserving their performance guarantees even in adversarial settings.

\subsubsection{Complexity Attacks Against Probabilistic Skipping-Based Data Structures}

This section provides a concise overview of so-called \emph{complexity attacks} targeting PSDS. Previous research has identified clear vulnerabilities in hash tables and skip lists, but these works lack formal security analysis and rigorous proofs of security when potential mitigations are put forth. Hash tables have received the most attention, while skip lists have been addressed (to our knowledge) in only a single paper in this context. Further, to our knowledge, no prior work has examined complexity attacks against treaps. This absence is consistent with our finding that treaps possess inherent resistance to such attacks.

\paragraph{Hash Tables} Assuming a hash table's internal hash function has ``good'' collision-resistance properties, the amortized average-case complexity of insertions, deletions, and look-ups is~$O(1)$. For these efficiency reasons, hash tables are widely used in many applications such as implementing associative arrays~\cite{mehlhorn2008hash} and sets~\cite{blandy2021programming} in many programming languages, in cache systems~\cite{istvan2015hash}, as well as for database indexing~\cite{zobel2001memory}.

However, this average-case performance relies on a critical assumption: that the data inserted into a hash table is independent of the (potentially randomly selected) hash function used to map key-value pairs to buckets. This assumption fundamentally breaks down in adversarial scenarios where an attacker can deliberately craft insertions that exploit knowledge of the hash function or its outputs. Given the ubiquity of hash tables in modern computing systems, numerous researchers \cite{paxson1999bro, CrosbyW03, bar2007remote, eckhoff2009hash, klink2011efficient, aumasson2012hash,bottinelli2025hash} have investigated techniques to compromise the data structure, forcing operations to degrade from expected $O(1)$ to worst-case $O(n)$ time complexity, where $n$ represents the total number of elements in the structure. These adversarial approaches typically constitute complexity attacks that strategically engineer inputs causing multi-collisions -- deliberately exploiting hash function properties to force numerous distinct keys into identical buckets.

Crosby and Wallach~\cite{CrosbyW03} demonstrated denial-of-service attacks via complexity attacks in applications using hash tables, such as the Bro intrusion detection system~\cite{paxson1999bro}, by forcing collisions with weak, fixed hash functions. They suggested universal hashing~\cite{carter1977universal} as a mitigation, though without any formal guarantees. Klink and Walde~\cite{klink2011efficient} showed similar CPU exhaustion attacks on web servers (e.g., PHP, ASP.NET, Java), only using a single carefully crafted HTTP request. Aumasson et al.\cite{aumasson2012hash} further revealed vulnerabilities in hash tables using non-cryptographic hash functions (like MurmurHash and CityHash\cite{appleby2016smhasher}), proposing SipHash~\cite{aumasson2012hash} as a secure alternative -- which is widely adopted but lacks a holistic formal analysis as it comes to security of hash tables in adversarial settings. Complexity attacks have also been shown effective in causing denial-of-service against flow-monitoring systems~\cite{eckhoff2009hash}. Further, the use of salting was undermined by remote timing attacks~\cite{bar2007remote}. Recently, Bottinelli et al.~\cite{bottinelli2025hash} found nearly a third of QUIC implementations vulnerable to similar attacks. Despite these works and many proposed defenses, no formal framework exists for the provable security of (keyed) hash tables against adaptive adversaries. We address this gap by introducing the first rigorous security model for this setting, along with formal proofs establishing bounds on adversarial runtime degradation.

\paragraph{Skip Lists}
In the original skip list paper~\cite{pugh}, it is noted that it is imperative to keep the internal structure of the skip list hidden. Otherwise, adversarial users could observe the levels of individual elements and delete any element at a level greater than zero (the bottom layer). This would degenerate the structure to a simple linked list and force worst-case run time ($O(n)$) on subsequent operations after these deletions occur. 

Nussbaum and Segal~\cite{nussbaum2019skiplist} demonstrate that private internal structure alone fails to protect skip lists against this style of attack. They present a (remote) timing attack that correlates query response times with element heights, ultimately allowing adversaries to force all elements in the structure to the lowest level. Their adversarial model is notably limited: the adversary cannot access the internal skip list structure, the initial data collection is non-adversarially selected, and the original data collection must be preserved during the attack. While they propose a structure called the \emph{splay skip list} as a countermeasure, their solution lacks formal security analysis. Our work presents a significantly stronger adversarial model and provides a construction with formal security guarantees. We give an extensive commentary on~\cite{nussbaum2019skiplist} and vulnerabilities below. 

Nussbaum and Segal~\cite{nussbaum2019skiplist} show that keeping the internal structure of the skip list private is insufficient to protect against complexity attacks. We discuss their attack in more detail because it is instructive in light of how to model attacks and prove the properties of robust alternatives.
Nussbaum and Segal present a timing attack that allows an adversary to discover the levels at which specific elements reside through a series of queries and, in turn, correlate the time it takes to answer a query on a given element with the height of that element. After the heights of the elements are discovered, the simple deletion attack can be mounted. 

The specific attack they present includes several assumptions.

\begin{itemize}
    \item The size of the collection represented by the structure,~$n$, is known to the adversary,~$\advA$.
    \item Each node in the structure holds a unique value.
    \item The well-ordered universe~$\univ$ is known and is of size~$O(n)$.
    \item The runtime of the search algorithm in the structure is consistent. That is, a search for the same value will yield the same runtime each time the search is executed.
\end{itemize}

Further, their adversarial model is the following. 

\begin{itemize}
    \item $\advA$ is given a skip list containing some collection of data,~$D$ that was selected by some (non-adversarial) process. 
    \item The adversary, $\advA$ does not have access to the internal structure of the skip list at any point. $\advA$ can only interact with the structure through oracles that provide search, insertion, and deletion functionality to the structure that is under attack.
    \item After the completion of the attack,~$\advA$ is required to have altered the skip list it interacts with such that it contains the original~$D$ represented by the structure (before any adversarial interaction occurs) and the level that all (or nearly all) the elements reside at is the first.  
\end{itemize}

The attack in this setting works by first running the timing attack to discover the level at which the elements in the structure exist (and, on the first iteration, which elements from~$\univ$ are present in the structure). Then all elements with a level greater than zero (exist at high level than the initial later) are removed. This set of removed elements are reinserted. These steps are repeated until (nearly) all the elements in the structure reside at level zero and the original collection represented by the structure is conserved -- thereby, degrading the representation of this collection to (nearly) a flat singly-linked list. 

As a countermeasure, the splay skip list structure is presented~\cite{nussbaum2019skiplist}.  The approach is to swap the levels of certain elements during a search query, thereby preventing the adversary from discovering information about the level where any particular element resides (as they are not fixed). The structure is believed to prevent the timing attack from being effective, but no formal analysis of the security of the structure is given. 

We again note that the adversarial setting that is given in~\cite{nussbaum2019skiplist} is rather limited. It assumes the adversary does not have access to the internal structure of the skip list, nor the ability to control the initial collection of data the skip represents. Further, it requires the adversary to conserve the initial data collection~$D$ that the skip list represents before any adversarial interaction occurs. We present a much stronger adversarial model in our work and a construction that satisfies this definition.

The authors propose a new structure that is believed to prevent the timing attack they present; however, as previously stated, no formal security analysis is given. 
Indeed, the splay skip list is still vulnerable to attacks, as demonstrated by the following scenario. Consider a collection~$D$ of elements represented by a splay skip list, where a total order is defined on the universe in which~$D$ resides. Suppose there exists an element~\( d \) such that~\( x_1 \leq d \leq x_2 \) for every pair of elements~\( x_1, x_2 \in D \), where~$x_1 \neq x_2$. For a specific order, $x_1 \leq d_1 \leq x_2 \leq d_2 \leq \ldots$ for~$x_i \in D$ and~$d_i \notin D$, an adversary can exploit this by conducting search queries for the intermediary elements $d_i$. 

Unlike searches for elements~$x_i \in D$, which would trigger the splay mechanism, searches for these intermediary elements~$d_i \not\in D$ bypass the splay security mechanism. The runtimes required to (not) find these intermediate nodes, however, still uniquely determine the height of elements contained in~$D$.\footnote{Compared to searching for elements~$x_1,x_2,\ldots$ as described in the original attack, the runtimes for searching~$d_1,d_2,\ldots$ only change by a constant factor (one extra step to find that the~$d_i \not\in S$) .} After the discovery of the heights of the elements contained in~$D$, the trivial deletion attack could be carried out as before.