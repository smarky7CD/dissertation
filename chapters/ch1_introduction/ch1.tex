\chapter{Introduction}

Data structures define representations of (possibly dynamic) sets or multisets, along with the operations that can be performed on these representations. Efficient data structures are crucial for designing efficient algorithms~\cite{clrs}. The development and analysis of data structures has largely been driven by operational concerns, e.g., efficiency, ease of deployment, support for broad application. Security concerns, on the other hand, have traditionally been treated as afterthoughts (at best). However, recent research has highlighted that many widely-used data structures do not behave as expected when in the presence of adversaries that have the ability to manipulate the data they represent. Furthermore, complex, modern protocols with sophisticated security goals increasingly rely on bespoke data structures as fundamental components of their designs. It is therefore both timely and prudent to apply the provable security paradigm to data structures themselves.


Consider, the family of \emph{compressing probabilistic data structures} (CPDS). The use of CPDS has grown rapidly in recent years in correlation with the rise of distributed applications producing and processing colossal amounts of data. These structures provide compact representations of (potentially massive) data collections, and support a small set of queries.  The trade-off for compactness is that query responses are only guaranteed to be ``close" to the true answer (i.e., if the query were evaluated on the full data) with a certain probability. A canonical example is the Bloom filter~\cite{bloom1970space} which supports set-membership queries (\emph{Does element $x$ appear in the data?}).  Bloom filters have found widespread use in applications such as caching~\cite{maggs2015}, database query optimization~\cite{dean2006}, search engine indexing~\cite{goodwin2017bitfunnel}, and even Bitcoin wallet synchronization~\cite{bip-0037}.

The probabilistic guarantee on the correctness of responses assumes that the data represented by the Bloom filter is independent of the randomness used to sample the hash functions that are used to populate the filter, and to compute query responses.  This is equivalent to providing correctness guarantees in the presence of adversarial data sets and queries that are \emph{non-adaptive}, i.e., made in advance of the sampling of the hash functions.  Recent research, however, has revealed that many data structures, including Bloom filters, perform poorly under adaptive adversaries, which tailor queries based on previous responses and knowledge of the underlying hash functions~\cite{naor2015bloom,clayton2019,CCS:FPUV22,filic2025deletions}. Similar vulnerabilities have been demonstrated for HyperLogLog structures~\cite{PatersonR22}, which estimate the number of distinct elements in a collection~\cite{flajolet2007hyperloglog}. Another important subclass of CPDS is the family of compact frequency estimators (CFEs), which includes structures such as Count-,in sketch and HeavyKeeper. Unlike Bloom filters, which answer membership queries, CFEs estimate the frequency of elements in a data stream. Despite their increasing adoption in network monitoring, stream processing, and heavy hitter detection, the formal analysis of CFEs has lagged behind their practical deployment. In particular, their robustness under adversarial conditions remains largely unexplored.

Another critical family of data structures is what we refer to as \emph{probabilistic skipping-based data structures} (PSDS), including  hash tables, skip lists, treaps, skip graphs, and randomized meldable heaps. Unlike CPDS, these structures are not space-efficient, but, in turn, offer exact answers to queries. Their design leverages randomness to achieve fast average-case performance -- often constant or logarithmic time for search, insertion, and deletion -- but with worst-case runtimes linear in the collection size. This randomness, while beneficial for expected performance, creates an attack surface: adversaries can exploit structural weaknesses to force worst-case behavior.

This is exemplified by complexity attacks against hash tables, where an adversary crafts input patterns that induce excessive hash collisions, resulting in performance degradation to linear time. While the underlying idea (exploiting structural dependencies in hashing) may seem conceptually simple, the real-world consequences are severe, including denial-of-service (DoS) vulnerabilities in many widely used applications~\cite{CrosbyW03,klink2011efficient,aumasson2012hash,rosen2014netfilter,bottinelli2025hash}. Despite a range of proposed mitigations, formal security models for these attacks and provable guarantees for the mitigations are conspicuously lacking. Even less is known about how other PSDS structures, such as skip lists, treaps, zip trees, and randomized meldable heaps, behave in adversarial settings. Notably, the only substantive work addressing adversarial behavior in PSDS beyond hash tables is that of Nussbaum and Segal, who demonstrated a timing side-channel attack against skip lists~\cite{nussbaum2019skiplist}.

The need for provably robust data structures is thus not merely theoretical, but essential for securing modern systems against adaptive adversaries. This dissertation advances this frontier by investigating attacks and constructing formally secure variants of CPDS and PSDS, with a particular emphasis on compact frequency estimators (a subclass of CPDS) and hash tables, skip lists, and treaps (PDSS). By doing so, we aim to provide both a rigorous foundation for secure data structures and practical tools for safeguarding real-world applications.

\section{Thesis Statement}

The goal of this dissertation is to rigorously analyze data structures in adversarial environments, specifically focusing on both compressing probabilistic data structures and probabilistic skipping-based data structures, and to construct performant and provably robust variants of these structures. The emphasis is on adaptive adversaries, who are capable of selecting queries and data inputs based on prior interactions with the structure, knowledge of the randomness used to initialize the structure, and the representation the structure has collection for a given data collection.

Therefore, the central thesis of this dissertation is:

\emph{For compact frequency estimators (a subclass of compressing probabilistic data structures) and probabilistic skipping-based data structures (including hash tables, skip lists, and treaps), formal adversarial models that capture the adaptive ability of adversaries can be defined under which these structures are provably insecure. Specifically, these models capture scenarios in which an adversary, with knowledge of the structure’s parameters, query responses, and, in certain cases, initialization choices and representations, can degrade correctness or performance guarantees beyond acceptable thresholds. It is further claimed that, for these same adversarial models, it is possible to construct new variants of these data structures that are provably robust, with explicit, formal guarantees on their correctness, performance, and security under attack}

\section{Contributions}

In addressing the goals of formalizing the security of compact frequency estimators and probabilistic skipping-based data structures, and in providing provably robust versions, this dissertation makes the following contributions:

\paragraph{Compact Frequency Estimators in Adversarial Environments} Count-min sketch (CMS) and HeavyKeeper (HK) are two realizations of compact frequency estimators (CFEs), a subclass of compressing probabilistic data structures that maintain a compact summary of (typically) high-volume streaming data. CFEs provide approximate estimates of the number of times a particular element has appeared in the stream. They often serve as foundational structures in systems identifying the highest-frequency elements (e.g., top-$K$ elements, heavy hitters, elephant flows). Traditionally, the probabilistic guarantees on the accuracy of CFEs are proved under the implicit assumption that stream elements are independent of the internal randomness of the structure—in other words, under the assumption of non-adaptive adversaries. However, in many practical scenarios, particularly those involving malicious actors incentivized to manipulate the data stream, this assumption does not hold. We demonstrate that both CMS and HK can be forced to make significant estimation errors via concrete attacks exploiting adaptivity. These attacks are analyzed both analytically and experimentally, with tight agreement between theory and practice. Unfortunately, our results suggest that such vulnerabilities may be inherent to sketch-based CFEs with parameters practical for real-world use. On a positive note, we introduce a new CFE, \emph{Count-Keeper}, which can be viewed as a composition of CMS and HK. Count-Keeper yields estimates that are typically more accurate (by at least a factor of two) than CMS for "honest" streams; our adaptive attacks are less effective (and more resource-intensive) against Count-Keeper; and Count-Keeper uniquely supports flagging suspicious estimates -- an ability absent in CMS, HK, and, to our knowledge, any other known CFE.

\paragraph{Compact Frequency Estimators in the Wild: A Case Study of Redis} Redis (Remote Dictionary Server) is a general-purpose, in-memory database that supports a rich array of functionality, including various CPDS, and in particular, two CFEs: CMS and Top-K (based on HK). As aforementioned, CFEs typically perform well on average-case inputs, their performance can degrade severely under adaptive adversaries. Given Redis’s wide deployment across diverse applications, it is crucial to evaluate the resilience of these CFEs under worst-case scenarios, specifically adversarial inputs. We conduct a comprehensive analysis of Redis’s CFE implementations, detailing deviations from the structures as described in the literature. We demonstrate that these deviations enable four novel attacks, each more severe -- or outright impossible -- compared to attacks on the generic versions of the CFEs. We highlight the critical role of Redis’s choice to use non-cryptographic hash functions in the severity of these attacks. Finally, we discuss potential countermeasures to mitigate these vulnerabilities.

\paragraph{Provably Robust Probabilistic Skipping-Based Data Structures} Probabilistic skipping-based data structures -- such as hash tables, skip lists, and treaps -- support efficient operations through randomized hierarchies that enable "skipping" elements, achieving sublinear query complexity in the average case for perfectly correct responses. These structures are critical in performance-sensitive systems where correctness is essential and efficiency is highly desirable. While simpler than deterministic alternatives like balanced search trees, these structures traditionally assume that input data is independent of the structure’s internal randomness and state -- an assumption that breaks down in adversarial environments. Under adaptive adversaries, this can lead to significant degradation in query performance. We present adaptive attacks on hash tables, skip lists, and treaps that, in the case of hash tables and skip lists, induce exponential performance degradation compared to the input-independent setting. While attacks on hash tables have been well studied, our attacks on skip lists and treaps offer new insights into vulnerabilities in probabilistic skipping-based data structures. In response, we propose simple and efficient modifications to these structures, yielding provably secure variants under adaptive adversaries. Our approach is formalized through the \emph{Adaptive Adversary Property Conservation} (AAPC) framework, a general security notion capturing deviation from expected efficiency guarantees in adversarial settings. Using this framework, we present rigorous robustness proofs for our proposed variants. Lastly, we conduct experiments whose empirical results align closely with our analytical predictions.

\section{Outline and Publications}

The remainder of this dissertation is organized as follows. \Cref{chap:background} introduces the necessary notation and syntax used throughout the document, as well as key terms and a review of related work. \Cref{chap:cfe} examines compact frequency estimators in adversarial environments. \Cref{chap:redis} presents our analysis of compact frequency estimator implementations in Redis and their limited robustness under adversarial conditions. \Cref{chap:psds} focuses on probabilistic skipping-based data structures, providing robust efficiency guarantees. Finally, \Cref{chap:conclusion} offers concluding remarks and discusses potential directions for future work.

This dissertation is based on the following publications\footnote{Publications with a majority European collaboration use alphabetical author ordering.}:

\begin{itemize}
    \item \Cref{chap:cfe} is based on:\\
    Sam A. Markelon, Mia Filić, and Thomas Shrimpton. 2023. Compact Frequency Estimators in Adversarial Environments. In Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security (CCS '23).

    \item \Cref{chap:redis} is based on:\\
    Mia Filić, Jonas Hofmann, Sam A. Markelon, Kenneth G. Paterson, and Anupama Unnikrishnan. 2025. Probabilistic Data Structures in the Wild: A Security Analysis of Redis. In Proceedings of the Fifteenth ACM Conference on Data and Application Security and Privacy (CODASPY '25).

    \item \Cref{chap:psds} is based on:\\
    Marc Fischlin, Moritz Huppert, and Sam Markelon. 2025. Probabilistic Skipping-Based Data Structures with Robust Efficiency Guarantees. In submission to the 2025 ACM SIGSAC Conference on Computer and Communications Security (CCS '25).
\end{itemize}